# Introduction to the Computing Landscape
If you are new to programming, or perhaps have been able to get by using scripting languages only,
you might not have been introduced to the other options. Some of the concepts presented here
lay the foundations for the choices dictating the rest of the guide.
Though the guide has made some clearly defined choices about which tools to use, you should at all times
use the right tool for the job. Not only in which language or framework you might choose,
but in how you put together and design your systems using those tools. Part of the guide's
strategy is to introduce you to quite a lot of tools and concepts, also known as the learn
what to Google strategy, and then going into greater detail about core concepts and concepts
especially relevant to your specialization.
The guide will introduce concepts that aid some programs in producing faster and results than others.
An important factor is limitations. Usually, the word limitations carries a negative connotation,
very few people think less freedom sounds enticing, but in computing limitations can be a wonderful
thing to have and set. Especially, once you are past the first prototype. In some cases, even when prototyping.

## Scripting Languages
Chill out, take things one line of code at a time.  
Scripting languages aren't compiled, but run one line at a time.
This leaves the system unable to look beyond the current line of code,
unless you add a compiler to the mix, whic usually takes a look at all of your code.

[Python](https://en.wikipedia.org/wiki/Python_(programming_language)) is likely the
scripting language you are most familiar with.  
Very popular due to its apparent ease-of-use. Quite slow in its raw form.  
The main advantage of vanilla python is the ability to glue together a number of libraries  
written in other languages. In time, improvements have been made, such as putting type hints  
into your code SUCH AS, which helps catch errors and gives more informative function definitions.

In general, if other people reading your code must read the high-quality comments,
that you definitely remembered to write... right?, then you are laying the foundation of a
codebase that will frustrate people, probably including yourself.
Python is easy to write at first, but the lack of a compiler can leave your long running code to fail
just at the moment it is about to save the results because your forgot you were trying to save the  
wrong type.

Python does have additional tools you can use to compile it. This allows for additional verification
and performance improvements, but without additional limitations and indications of your intention,
it might not be possible to optimize your code as much as a language which leaves things less
open to interpretation.

## Compilers  
A compiler processes the given code in one or more steps.
In some steps it might verify that all of your code is correct, it might perform transform and optimize your code,
it might change it into different representations like byte code or machine code. Some compilers strictly function
ahead-of-time in an operation like ```some_compiler -compile my_file.code``` and output a runnable executable,
specifically for your type of machine.
Most compilers require additional constraints to transform and improve your code.

Imagine you ask someone to go get you some milk every Thursday at 12.
An unreasonably pedantic person (engineer) might be ready at 12 every Thursday and ask you what type of milk
you would like today.
It seems annoying and strange. You know what type of milk you like, the pedantic person should know what
type of milk you like. That bastard! If you instead asked for X brand skim milk delivered at 12 every Thursday,
the pedantic person might even try to optimize the process before the delivery day.
If it was milk with a long expiration day, they could buy it in bulk and just have it ready for you.
That unreasonably pedantic person is the compiler of whatever programming language you are using.
It will go far to help you, it just doesn't perform well in ambivalent circumstances.
Compilers are genereally not allowed to guess in a way that might functionally alter your code, such  
as reducing the level of precision.

The languages in the compiled languages are all designed with at least one compiler, usually  
compiling to byte code or machine code.  
However, it is possible to write a compiler after the fact. [Cython](https://cython.org/) is one such compiler.  
It benefits quite a bit from having the user perform additional annotations of their python code,  
allowing for a decent speedup.

Other compilers act Just-In-Time (JIT). Just as you want to run your code it will compile it.
While this seems a bit weird, why not just compile it once and for all, this can allow the compiler to
optimize the program specifically for your machine. The
[Java HotSpot VM](https://docs.oracle.com/en/java/javase/17/vm/java-virtual-machine-technology-overview.html#GUID-982B244A-9B01-479A-8651-CB6475019281)
even tries to optimize your code as it runs. If allowed to become a long-running process it can
swap byte code for compiled machine code. In general, JIT compilers increase the startup time
of your code, afterall, it has to compile it, just like the AOT compiler. Some JIT compilers
save the compilation artifacts (the outputs of the compilation process) for later to merely
reload it, but that won't help you much while you are developing your code. Some libraries and
frameworks such as [numba](https://en.wikipedia.org/wiki/Numba) perform JIT compilation of your
annotated code to optimize the performance.

## Compiled Languages
In some languages like [C](https://en.wikipedia.org/wiki/C_(programming_language)),
[C++](https://en.wikipedia.org/wiki/C%2B%2B) and
[Rust](https://en.wikipedia.org/wiki/Rust_(programming_language)), machine code is the outcome.
That machine code can be quite platform specific, both because of the operating system and the
hardware, and is binary. 1's and 0's!
These three languages are not garbage collected (more on that later).

Another quite popular language is [Go](https://en.wikipedia.org/wiki/Go_(programming_language)),
which also compiles to machine code, but is garbage collected.
[Julia](https://en.wikipedia.org/wiki/Julia_(programming_language)) has more of a scientific/numerical
focus, but features garbage collection, JIT compilation and can use either a runtime or compile to
a standalone binary.

Other languages like [Java](https://en.wikipedia.org/wiki/Java_%28programming_language%29) and
[C#](https://en.wikipedia.org/wiki/C_Sharp_(programming_language)) compile to something called bytecode,
which can then be interpreted by a process virtual machine. Thus all Java programs compile to the same
bytecode, regardless of whether it's supposed to run on a Mac or Windows platform.
The bytecode is then interpreted, sometimes optimized as well,
at runtime by a virtual machine written for that specific platform.

[Javascript](https://en.wikipedia.org/wiki/JavaScript) is a just-in-time compiled language running on most web pages.  
It can occassionally have a reasonable speed due to the optimizing runtime.  
Heavy development has tuned the widely used V8 runtime to improve Javascripts performance.  
Writing Javascript can seem easy, but the amount of things you are allowed to do,  
but shouldn't, can make it an arduous experience once the errors start piling up.  
The advantage is highly portable code, because everything is essentially just a string... including numbers.  

## The Guide and Languages
As you can probably see in the column on the left... the guide will be using Rust from here on out.
If you read the section on GPU programming, you will see there are no easy, one-size-fits-all,
solutions. Thankfully, the guide has clear goals and limitations.
To help you get familiar with new topics, we only need reasonable performance and for all
the code to be runnable on most laptops.  
After all, it's not much fun playing around with things on someone else's computer.  
Most importantly, the setup process should be easy and not make you want to stress-eat
the contents of your entire fridge when going through the installation process.
As such the guide will mainly use Rust and the GPU API wgpu. The guide will in all cases that do not require
graphics output only concern itself with pure computation through wgpu, which makes setup quite a bit simpler.
wgpu is an abstraction layer that runs whatever GPU API it finds best suitable on your system. Having exact
control and the absolute best performance isn't as important for the guide as allowing as many people to
participate and learn as possible. After all, if it doesn't work on your laptop/desktop, you can't really
play around and have fun with it!

## \*GPU APIs and Languages
GPUs are some of the most readily available accelerators. Originally made for graphics, since around 2008
using them for general computation has been in focus as well. All graphics API's now also support general
computation. Usually it will be called a compute shader. Shader is the common name for a GPU program.
If running CUDA or OpenCL, it is called a kernel. The guide will mostly focus on the pure compute parts
of GPU APIs, except for the graphics specialization. Thus it will be assumed that if you are interested in
the graphics specialization you might already have done a graphics course or a tutorial such as
[LearnOpenGL](https://learnopengl.com/) or [Learn Wgpu](https://sotrh.github.io/learn-wgpu/).
It is worth noting that a compute shader using a graphics-based API, such as Vulkan, can perform just as
well as an implementation in a compute-only API, such as CUDA. One example of this is
[VkFFT](https://github.com/DTolm/VkFFT). A GPU API is all the
stuff that you have to write in your code that is not the function itself that you want to run. It could be calls
like creating a connection to the GPU, allocating memory on the GPU, transferring the contents of a buffer to the
memory you just allocated on the GPU or launching your shader/kernel and transferring the results back to the CPU.
The GPU languages themselves vary with the APIs. Some APIs, such as Vulkan,
can take an intermediate representation called SPIR-V, this allows the user to write in any shading language, or
even Rust in [one case](https://github.com/EmbarkStudios/rust-gpu), as long as it is compiled to SPIR-V. Usually a
shading language will look a lot like C/C++, but have its own distinct rules. You can't always make the same
assumptions.

The rest of this section is an overview of the various available GPU APIs.

### Web APIs
An often used strategy for making your programs as widely available as possible, is to use web-based techonology.
Whatever browser you, or the end user is using supports some GPU APIs. For a long time it has been
[WebGL](https://en.wikipedia.org/wiki/WebGL), which is a subset of OpenGL. WebGL has a version 2.0, which was
finally supported by all major browsers not too long ago. The 2.0 version brought support for compute shaders with it.
The modern newcomer is [WebGPU](https://en.wikipedia.org/wiki/WebGPU) which has a way of doing things that more
closely resembles modern APIs such as Vulkan, DirectX 12 and Metal. It is not widely supported in browsers, outside
of developer modes. Until then, the [wgpu](https://wgpu.rs/) abstraction can be used. It has an API which follows
the WebGPU specification, with some optional extensions for more features, but under the hood it uses whatever API
it deems best for the current platform. Once the support for WebGPU becomes widespread, it can merely choose to run
using WebGPU instead. In general, you will find that most frameworks or APIs which have to support a lot of things
will be centered around the lowest common denominator. However, tools such as Vulkan and wgpu do allow you to query
the system you are on for support of an extension, which does allow access to specialized features. You may
however, end up with several versions of some elements of your code, based on whether some feature is there or not.

### Platform-Specific APIs
Some GPU APIs are specific to specific operating systems. 
[DirectX11](https://en.wikipedia.org/wiki/DirectX#DirectX_11) and
[DirectX12](https://en.wikipedia.org/wiki/DirectX#DirectX_12) targets Windows and XBox platforms, while
[Metal](https://en.wikipedia.org/wiki/Metal_(API)) targets Apple devices. The guide won't concern itself too much
with these. DirectX11 is somewhat similar to OpenGL, while DirectX12 and Metal are from the same, more low-level,
generation as Vulkan. Metal however, seems to be a bit less low-level compared to DirectX12 and Vulkan.

### Cross-Platform APIs
[OpenGL](https://en.wikipedia.org/wiki/OpenGL) and
[Vulkan](https://en.wikipedia.org/wiki/Vulkan) are cross platform. OpenGL hasn't seen any updates for a while. Vulkan on the other hand is a low level, but generally popular API. It puts a lot of responsibility on to the programmer, but works on Windows and Linux, as well as Intel, Nvidia and AMD GPUs. It even works fairly decently on Apple devices thanks to [MoltenVK](https://moltengl.com/moltenvk/). Another cross-platform tool is
[wgpu](https://wgpu.rs/), introduced earlier. It is also the one that will be used in the guide for GPU code.

### Compute APIs
Some GPU APIs are not for graphics, such as [CUDA](https://en.wikipedia.org/wiki/CUDA)
[OpenCL](https://en.wikipedia.org/wiki/OpenCL). OpenCL is cross-platform (works on all GPUs), as well as compiling to FPGAs, DSPs and parallelized CPU code. On the other hand CUDA is just for Nvidia GPUs.
CUDA is widely used in scientific computing and mostly dominates academia. Both CUDA and OpenCL have their kernels
written in a specialized version of C++.

### Shader Languages
Shader languages are languages specifically tailored for the combined graphics/compute APIs.
Graphics APIs have some specific functionality which the language has to support.
Usually you will find support for small vectors and matrices (up to 4x4) and various types you might not find
on the CPU such as fp16. They will also usually have something called textures, bindings, samplers and built-in variables.Â¨
You don't need to worry about that very much in the guide.
[GLSL](https://en.wikipedia.org/wiki/OpenGL_Shading_Language),
[HLSL](https://en.wikipedia.org/wiki/High-Level_Shader_Language),
[WGSL](https://en.wikipedia.org/wiki/Shading_language#WebGPU_Shading_Language) and
[MSL](https://en.wikipedia.org/wiki/Metal_(API)) are all shading languages developed for graphics APIs. 
OpenGL, DirectX, WebGPU and Metal, respectively. GLSL is also the main language of Vulkan,
but HLSL is also seeing rising popularity. Lately, the tooling for cross compiling and running the
same shaders on different graphics APIs has become a lot better. Shaders can be compiled to SPIR-V,
an intermediate representation, sort of like the byte code we discussed earlier. 
This allows the platform independent SPIR-V to be translated to the specific instructions
the GPU the code is actually run on. One tool for compiling shaders is [naga](https://github.com/gfx-rs/naga).

## \*Domain Specific Languages and Frameworks
Shading languages all benefit from limitations and specializations from being specifically for graphics on a GPU.
Another form of limitation is domain specific languages and frameworks. One such framework you might know of is
[Pytorch](https://pytorch.org/). You are generally supposed to formulate your neural network as a graph and not
just a sequence of operations. This allows PyTorch to have a clearer picture of what it is you want to do. It can
check that all dimensions fit before running the training loop and it can optimize the process. Taking things even
further PyTorch even has its own compiler from [version 2.0](https://pytorch.org/get-started/pytorch-2.0/).  

Another way of achieving speedy results in a flexible format is retrofitting an existing language, in this case
Python, with a slightly different language. [taichi](https://www.taichi-lang.org/) combines a domain specific
language to JIT compile highly performant code, which can also run graphics, to whatever platform you are running
on. It can do this because of increased requirements of the user. Namely, annotating their code and setting
limitations. [Halide](https://halide-lang.org/) on the other hand restricts itself to be a JIT-compiled language embedded in C++ made specifically for working with images and tensors.

[Futhark](https://futhark-lang.org/) is a language made specifically for replacing the parts of your code which need to be fast. As such it is not a general language and can make opinionated choices which allows it to generate more performant programs.
